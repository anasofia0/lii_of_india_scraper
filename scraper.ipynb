{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all law case links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search queries\n",
    "queries = ['forced labour',\n",
    "            'forced labor',\n",
    "            'human trafficking​',\n",
    "            'child labor',\n",
    "            'child labour',\n",
    "            'modern slavery',\n",
    "            'slavery']\n",
    "\n",
    "# required header\n",
    "header = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:128.0) Gecko/20100101 Firefox/128.0',\n",
    "          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/png,image/svg+xml,*/*;q=0.8'\n",
    "          }\n",
    "\n",
    "domain = 'http://www.liiofindia.org/'\n",
    "\n",
    "# base query template\n",
    "query_base = 'http://www.liiofindia.org/cgi-bin/sinosrch.cgi?method=boolean&query={}&meta=%2Fliiofindia&lii=LIIofIndia&mask_path=in%2Fcases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_law_urls(soup):\n",
    "    \"\"\"\n",
    "    Get all law case urls from search page\n",
    "    \"\"\"\n",
    "    law_cases_url = []\n",
    "    law_cases_list = soup.find('ol')\n",
    "\n",
    "    # some queries return empty response\n",
    "    if law_cases_list == None:\n",
    "        return None\n",
    "    \n",
    "    law_cases_list = law_cases_list.find_all('li')\n",
    "    \n",
    "    for case in law_cases_list:\n",
    "        for item in case.p.contents:\n",
    "            if item.name == 'a':\n",
    "                url_case = item['href']\n",
    "                title = item.contents[0]\n",
    "                year = [int(y) for y in re.findall(r'\\d{4}', title)]\n",
    "                year = min(year) if year != [] else None\n",
    "            elif item.name == 'small':\n",
    "                database = item.contents[1].contents[0]\n",
    "        \n",
    "        # check if its law case\n",
    "        if re.search(r'\\s[vV][sS]?\\.?\\s', title):\n",
    "            law_cases_url.append({'url': url_case,\n",
    "                                'title': title,\n",
    "                                'year': year,\n",
    "                                'database': database})\n",
    "    return law_cases_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forced labour: 201\n",
      "forced labor: 1\n",
      "human trafficking​: 0\n",
      "child labor: 13\n",
      "child labour: 240\n",
      "modern slavery: 0\n",
      "slavery: 248\n"
     ]
    }
   ],
   "source": [
    "law_cases = []\n",
    "for query in queries:\n",
    "    query_cases = []\n",
    "    url = query_base.format(query.replace(' ', '+'))\n",
    "    soup = BeautifulSoup(requests.get(url, headers=header).content, \"html.parser\")\n",
    "\n",
    "    search_pages = []\n",
    "    for url in soup.find_all('a'):\n",
    "        if url.has_attr('href') and re.match(r'.*offset=\\d+0.*', url['href']):\n",
    "            search_pages.append(url['href'])\n",
    "    search_pages = ['http://www.liiofindia.org' + page for page in list(set(search_pages)) if 'http://www.liiofindia.org' not in page]\n",
    "\n",
    "    # search links in first page\n",
    "    urls = get_law_urls(soup)\n",
    "    if urls != None:\n",
    "        query_cases += urls\n",
    "\n",
    "        # search in offset pages\n",
    "        for page in search_pages:\n",
    "            soup = BeautifulSoup(requests.get(page, headers=header).content, \"html.parser\")\n",
    "            query_cases += get_law_urls(soup)\n",
    "\n",
    "        # update query value\n",
    "        for idx, case in enumerate(query_cases):\n",
    "            query_cases[idx]['query'] = query\n",
    "        \n",
    "        # add to law cases list\n",
    "        law_cases += query_cases\n",
    "    \n",
    "    print(f'{query}: {len(query_cases)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'law_cases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = pd.DataFrame(\u001b[43mlaw_cases\u001b[49m)\n\u001b[32m      2\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mtest.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'law_cases' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(law_cases)\n",
    "df.to_csv('search.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>database</th>\n",
       "      <th>query</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.liiofindia.org/cgi-bin/disp.pl/in/c...</td>\n",
       "      <td>PEOPLE'S UNION FOR DEMOCRATIC RIGHTS &amp; ORS V U...</td>\n",
       "      <td>1982</td>\n",
       "      <td>High Court of Karnataka</td>\n",
       "      <td>forced labour</td>\n",
       "      <td>BHAGWATI, P.N.\\nBHAGWATI, P.N.\\nISLAM, BAHARUL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.liiofindia.org/cgi-bin/disp.pl/in/c...</td>\n",
       "      <td>PEOPLE'S UNION FOR DEMOCRATIC RIGHTS &amp; ORS V U...</td>\n",
       "      <td>1473</td>\n",
       "      <td>Supreme Court of India</td>\n",
       "      <td>forced labour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.liiofindia.org/cgi-bin/disp.pl/in/c...</td>\n",
       "      <td>PEOPLE'S UNION FOR DEMOCRATIC RIGHTS &amp; ORS V U...</td>\n",
       "      <td>1473</td>\n",
       "      <td>Supreme Court of India</td>\n",
       "      <td>forced labour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.liiofindia.org/cgi-bin/disp.pl/in/c...</td>\n",
       "      <td>BANDHUA MUKTI MORCHA V UNION OF INDIA &amp; ORS [1...</td>\n",
       "      <td>1983</td>\n",
       "      <td>High Court of Karnataka</td>\n",
       "      <td>forced labour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.liiofindia.org/cgi-bin/disp.pl/in/c...</td>\n",
       "      <td>BANDHUA MUKTI MORCHA V UNION OF INDIA &amp; ORS [1...</td>\n",
       "      <td>1151</td>\n",
       "      <td>Supreme Court of India</td>\n",
       "      <td>forced labour</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  http://www.liiofindia.org/cgi-bin/disp.pl/in/c...   \n",
       "1  http://www.liiofindia.org/cgi-bin/disp.pl/in/c...   \n",
       "2  http://www.liiofindia.org/cgi-bin/disp.pl/in/c...   \n",
       "3  http://www.liiofindia.org/cgi-bin/disp.pl/in/c...   \n",
       "4  http://www.liiofindia.org/cgi-bin/disp.pl/in/c...   \n",
       "\n",
       "                                               title  year  \\\n",
       "0  PEOPLE'S UNION FOR DEMOCRATIC RIGHTS & ORS V U...  1982   \n",
       "1  PEOPLE'S UNION FOR DEMOCRATIC RIGHTS & ORS V U...  1473   \n",
       "2  PEOPLE'S UNION FOR DEMOCRATIC RIGHTS & ORS V U...  1473   \n",
       "3  BANDHUA MUKTI MORCHA V UNION OF INDIA & ORS [1...  1983   \n",
       "4  BANDHUA MUKTI MORCHA V UNION OF INDIA & ORS [1...  1151   \n",
       "\n",
       "                  database          query  \\\n",
       "0  High Court of Karnataka  forced labour   \n",
       "1   Supreme Court of India  forced labour   \n",
       "2   Supreme Court of India  forced labour   \n",
       "3  High Court of Karnataka  forced labour   \n",
       "4   Supreme Court of India  forced labour   \n",
       "\n",
       "                                             content  \n",
       "0  BHAGWATI, P.N.\\nBHAGWATI, P.N.\\nISLAM, BAHARUL...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('search.csv')\n",
    "df['content'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(soup):\n",
    "    soup.find_all('h2')\n",
    "    title = soup.h2\n",
    "    document = title.find_next('p')\n",
    "\n",
    "    # remove footnote\n",
    "    document = re.sub(r'\\[\\nContext\\n\\] \\[\\nHide Context\\n\\]\\n(?:CommonLII|LIIofIndia):\\nCopyright Policy\\n\\|\\nDisclaimers\\n\\|\\nPrivacy Policy\\n\\|\\nFeedback\\nURL:\\s.*', '', document.get_text(strip=True, separator='\\n'))\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 703/703 [30:54<00:00,  2.64s/it]  \n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if not pd.isna(row.content): continue\n",
    "    sleep(0.01)\n",
    "    soup = BeautifulSoup(requests.get(row.url, headers=header).content, \"html.parser\")\n",
    "\n",
    "    # check if it is embbeded pdf\n",
    "    obj = soup.find('object')\n",
    "    if obj is not None and obj['type'] == 'application/pdf':\n",
    "        df.loc[idx, 'content'] = ''\n",
    "        continue\n",
    "\n",
    "    content = get_content(soup)\n",
    "    df.loc[idx, 'content'] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lii_india_modern_slavery.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df['content']==''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Embedded PDFs and extract their content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('lii_india_modern_slavery.csv')\n",
    "pdf_df = df[df.isnull().any(axis=1)]\n",
    "pdf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_downloaded = -1 # checkpoint\n",
    "data_path = './data/' # download path\n",
    "downloaded_files = [] # list of downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [13:26<00:00, 16.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(pdf_df.iterrows(), total=pdf_df.shape[0]):\n",
    "    if idx <= last_downloaded: continue\n",
    "    sleep(0.01)\n",
    "    soup = BeautifulSoup(requests.get(row.url, headers=header).content, \"html.parser\")\n",
    "    \n",
    "    obj = soup.find('object')\n",
    "    if obj is not None and obj['type'] == 'application/pdf':\n",
    "        file_path = obj['data'] # get file location in database\n",
    "        filename = file_path.replace('/', '_').strip('_').replace('in_cases_', '')\n",
    "        sleep(0.01)\n",
    "        content = requests.get(domain+file_path, headers=header).content # get file from database\n",
    "        with open(data_path+filename, 'wb') as f:\n",
    "            f.write(content)\n",
    "        downloaded_files.append((idx, filename)) # save idx and filename\n",
    "    elif 'There is no available HTML version of this document' in soup.get_text():\n",
    "        if file_path := re.search(r'(in\\/cases\\/.*\\.html)', row.url):\n",
    "            file_path = file_path.group(1).replace('html', 'pdf')\n",
    "            filename = file_path.replace('/', '_').strip('_').replace('in_cases_', '')\n",
    "            sleep(0.01)\n",
    "            content = requests.get(domain+file_path, headers=header).content # get file from database\n",
    "            with open(data_path+filename, 'wb') as f:\n",
    "                f.write(content)\n",
    "            downloaded_files.append((idx, filename)) # save idx and filename\n",
    "    else:\n",
    "        downloaded_files.append((idx, -1)) # save idx and -1 if download file not found\n",
    "\n",
    "    last_downloaded = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(downloaded_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list = [idx for idx, _ in downloaded_files]\n",
    "doc_content = []\n",
    "for idx, file in downloaded_files:\n",
    "    if file == -1:\n",
    "        doc_content.append('')\n",
    "    else:\n",
    "        doc = pymupdf.open(data_path+file)\n",
    "        content = ' '.join([page.get_text() for page in doc])\n",
    "        doc_content.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[idx_list, 'content'] = doc_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lii_india_modern_slavery.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs4",
   "language": "python",
   "name": "bs4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
